{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: GeForce GTX TITAN X (CNMeM is disabled, CuDNN 4007)\n",
      "/usr/local/lib/python2.7/dist-packages/theano/tensor/signal/downsample.py:5: UserWarning: downsample module has been moved to the pool module.\n",
      "  warnings.warn(\"downsample module has been moved to the pool module.\")\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from collections import deque\n",
    "import numpy as np\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import lasagne\n",
    "sys.path.append(\"..\")\n",
    "from qtable import QAgent, SimpleMaze\n",
    "from qnn import QAgentNN, wrap_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "maze = SimpleMaze()\n",
    "agent = QAgentNN(dim_state=(1, 1, 2), range_state=((((0, 3),(0, 4)),),),actions=maze.actions,\n",
    "                 learning_rate=0.01, reward_scaling=100,\n",
    "                 freeze_period=100,\n",
    "                 alpha=0.5, gamma=0.5, explore_strategy='fixed_epsilon', epsilon=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 33.00330033\n",
      "200 33.8983050847\n",
      "300 34.2857142857\n",
      "400 34.9344978166\n",
      "500 35.360678925\n",
      "600 35.3565114909\n",
      "700 35.2289884248\n",
      "800 34.6921075455\n",
      "900 34.9922239502\n",
      "1000 34.9040139616\n",
      "1100 34.8763474952\n",
      "1200 34.8027842227\n",
      "1300 34.7779561263\n",
      "1400 34.4657804037\n",
      "1500 34.137460173\n",
      "1600 34.3347639485\n",
      "1700 34.2121151137\n",
      "1800 33.9302544769\n",
      "1900 33.8680926916\n",
      "2000 33.9904826649\n",
      "2100 33.9202067517\n",
      "2200 33.8357428484\n",
      "2300 33.7738619677\n",
      "2400 33.8839474799\n",
      "2500 33.8524035206\n",
      "2600 33.8629851524\n",
      "2700 33.8685398896\n",
      "2800 33.836858006\n",
      "2900 33.7641168937\n",
      "3000 33.8180588434\n",
      "3100 33.7690631808\n",
      "3200 33.8875357408\n",
      "3300 33.9995878838\n",
      "3400 33.8072983991\n",
      "3500 33.8917400988\n",
      "3600 33.8696020322\n",
      "3700 33.8332114119\n",
      "3800 33.8078291815\n",
      "3900 33.8072122053\n",
      "4000 33.7581230484\n",
      "4100 33.7448559671\n",
      "4200 33.7132766094\n",
      "4300 33.6410577374\n",
      "4400 33.6932383797\n",
      "4500 33.6297735595\n",
      "4600 33.5179248033\n",
      "4700 33.5906232133\n",
      "4800 33.5781741868\n",
      "4900 33.566241951\n",
      "5000 33.5773285877\n",
      "5100 33.5791414274\n",
      "5200 33.5700451904\n",
      "5300 33.5570469799\n",
      "5400 33.6176305796\n",
      "5500 33.5693359375\n",
      "5600 33.5892514395\n",
      "5700 33.5748365436\n",
      "5800 33.6095497479\n",
      "5900 33.6086585019\n",
      "6000 33.6492625203\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-0d8519b6c5af>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     34\u001b[0m         \u001b[1;32mprint\u001b[0m \u001b[0mnum_episodes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1.0\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mcum_reward\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mcum_steps\u001b[0m\u001b[1;31m#, path\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[0mwin\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m50\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrolling_mean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mwin\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mepisode_reward_rates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwindow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mwin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_periods\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "# logging\n",
    "path = deque()  # path in this episode\n",
    "episode_reward_rates = []\n",
    "num_episodes = 0\n",
    "cum_reward = 0\n",
    "cum_steps = 0\n",
    "\n",
    "# repeatedly run episodes\n",
    "while num_episodes < 6000:\n",
    "    maze.reset()\n",
    "    new_state = maze.observe()\n",
    "    agent.reset(init_state=wrap_state(new_state))\n",
    "\n",
    "    path.clear()\n",
    "    path.append(new_state)\n",
    "    episode_reward = 0\n",
    "    episode_steps = 0\n",
    "\n",
    "    # interact and reinforce repeatedly\n",
    "    while not maze.finished():\n",
    "        action = agent.act()\n",
    "        new_state, reward = maze.interact(action)\n",
    "        agent.reinforce(new_state=wrap_state(new_state), reward=reward)\n",
    "\n",
    "        path.append(new_state)\n",
    "        episode_reward += reward\n",
    "        episode_steps += 1\n",
    "\n",
    "    cum_steps += episode_steps\n",
    "    cum_reward += episode_reward\n",
    "    num_episodes += 1\n",
    "    episode_reward_rates.append(episode_reward / episode_steps)\n",
    "    if num_episodes % 100 == 0:\n",
    "        print num_episodes, 1.0 * cum_reward / cum_steps#, path\n",
    "win = 50\n",
    "s = pd.rolling_mean(pd.Series([0]*win+episode_reward_rates), window=win, min_periods=1)\n",
    "s.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
